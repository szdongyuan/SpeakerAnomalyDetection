# DO NOT MOVE, UNLESS NECESSARY!!!

- module_name: "preprocess"

  module_config:
    preprocess_method: "sequence_process"
    preprocess_param:
      processor_list:
        - preprocess_method: "data_padding"
          preprocess_param:
            maxlen: 132300
        - preprocess_method: "stack_process"
          preprocess_param:
            processor_list:
              - preprocess_method: "mfcc"
                preprocess_param:
                  extraction_kwargs:
                    n_mfcc: 20
                    n_fft: 2048
                    hop_length: 256

- module_name: "model"

  module_config:

    model_name: "Transformer"

    model_init_config:
      input_len_1: 517
      input_len_2: 20
      layers_param:
        - layer_name: "TransformerEncoder"
          layer_kwargs:
            embed_dim: 20
            dense_dim: 256
            num_heads: 8
        - layer_name: "Flatten"
        - layer_name: "Dense"
          layer_kwargs:
            units: 64
            activation: "relu"
        - layer_name: "Dense"
          layer_kwargs:
            units: 2
            activation: "softmax"
      compile_param:
        optimizer: 'adam'
        loss: 'sparse_categorical_crossentropy'
        metrics:
          - accuracy

    model_fit_config:
      balance_sample_number: False
      cycles: 1
      epochs: 5
      batch_size: 30
      early_stop: False
      class_weight:
        0: 2
        1: 1

    model_predict_config:
      acc_req: 0.5