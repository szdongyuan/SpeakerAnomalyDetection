# DO NOT MOVE, UNLESS NECESSARY!!!

- module_name: "preprocess"

  module_config:

    preprocess_method: "stack_process"
    preprocess_param:
      processor_list:
        - preprocess_method: "mfcc"
          preprocess_param:
            extraction_kwargs:
              n_mfcc: 20
              n_fft: 2048
              hop_length: 512
#        - preprocess_method: "mel_spec"
#          preprocess_param:
#            extraction_kwargs:
#              n_fft: 2048
#              hop_length: 256
#        - preprocess_method: "zero_crossing_rate"
#          preprocess_param:
#            extraction_kwargs:
#              frame_length: 2048
#              hop_length: 256
#        - preprocess_method: "spectral_flatness"
#          preprocess_param:
#            extraction_kwargs:
#              n_fft: 2048
#              hop_length: 256

- module_name: "model"

  module_config:

    model_name: "Transformer"

    model_init_config:
      input_len_1: 126
      input_len_2: 20
      layers_param:
        - layer_name: "TransformerEncoder"
          layer_kwargs:
            embed_dim: 20
            dense_dim: 64
            num_heads: 8
        - layer_name: "Flatten"
        - layer_name: "Dense"
          layer_kwargs:
            units: 64
            activation: "relu"
        - layer_name: "Dense"
          layer_kwargs:
            units: 2
            activation: "softmax"
      compile_param:
        optimizer: 'adam'
        loss: 'sparse_categorical_crossentropy'
        metrics:
          - accuracy

    model_fit_config:
      balance_sample_number: False
      cycles: 2
      epochs: 10
      batch_size: 30
      early_stop: True
      class_weight:
        0: 8
        1: 1

    model_predict_config:
      acc_req: 0.8